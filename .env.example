# AION Environment Configuration
# Copy this file to .env and adjust values as needed

# ===========================================
# Main LLM Configuration (Llama 3.3 70B)
# ===========================================
AION_LLM_PROVIDER=local
AION_LLM_MODEL=meta-llama/Llama-3.3-70B-Instruct
AION_LLM_BASE_URL=http://localhost:8000/v1
# AION_LLM_API_KEY=  # Not needed for local models

# ===========================================
# Embedding Model Configuration (BGE-large)
# ===========================================
AION_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
AION_EMBEDDING_BASE_URL=http://localhost:8001/v1
AION_EMBEDDING_DIMENSION=1024

# ===========================================
# SOTA Agent Features
# ===========================================
# Tree-of-Thought settings
AION_TOT_MAX_DEPTH=5
AION_TOT_BRANCHING_FACTOR=3

# Chain-of-Thought settings
AION_COT_SELF_CONSISTENCY_SAMPLES=3

# Reasoning temperature (lower = more focused)
AION_REASONING_TEMPERATURE=0.3

# ===========================================
# Server Configuration
# ===========================================
AION_HOST=0.0.0.0
AION_PORT=8080
AION_DEBUG=false

# ===========================================
# Memory Configuration
# ===========================================
AION_MEMORY_MAX_ENTRIES=100000
AION_MEMORY_INDEX_TYPE=hnsw

# ===========================================
# Security
# ===========================================
AION_REQUIRE_APPROVAL_HIGH_RISK=true
AION_SANDBOX_MODE=true

# ===========================================
# Monitoring
# ===========================================
AION_ENABLE_METRICS=true
AION_ENABLE_TRACING=true
AION_LOG_LEVEL=INFO

# ===========================================
# Testing
# ===========================================
# Set to 1 to run integration tests with real LLM
AION_TEST_WITH_LLM=0
