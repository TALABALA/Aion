# AION - Artificial Intelligence Operating Nexus
# Core Dependencies

# Web Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
python-multipart>=0.0.6

# LLM Providers
openai>=1.12.0
anthropic>=0.18.0
httpx>=0.26.0

# Vector Search & Embeddings
faiss-cpu>=1.7.4
sentence-transformers>=2.3.0
transformers>=4.37.0

# Deep Learning
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# Computer Vision
opencv-python>=4.9.0
pillow>=10.2.0

# Scientific Computing
numpy>=1.26.0
scipy>=1.12.0
matplotlib>=3.8.0

# Graph Operations
networkx>=3.2.0

# Web Scraping
beautifulsoup4>=4.12.0

# Data Validation
pydantic>=2.6.0
pydantic-settings>=2.1.0

# Utilities
python-dotenv>=1.0.0
aiofiles>=23.2.0
tenacity>=8.2.0
structlog>=24.1.0
rich>=13.7.0

# Testing
pytest>=8.0.0
pytest-asyncio>=0.23.0

# Type Checking
mypy>=1.8.0

# ==================== Audio Processing ====================
librosa>=0.10.0
soundfile>=0.12.0
pydub>=0.25.0
audioread>=3.0.0

# Speech Recognition - Core
# Whisper via transformers (included above)

# Speaker Diarization
pyannote.audio>=3.1.0

# Speaker Recognition
speechbrain>=1.0.0

# ==================== SOTA Audio (Optional) ====================
# Uncomment these for state-of-the-art performance:

# Whisper-X: SOTA transcription with accurate word alignment
# pip install whisperx
# whisperx>=3.1.0

# Source Separation (Demucs): Separate vocals/instruments
# pip install demucs
# demucs>=4.0.0

# XTTS-v2: High-quality TTS with voice cloning
# pip install TTS
# TTS>=0.22.0

# Faster Whisper: Optimized inference (4x faster)
# pip install faster-whisper
# faster-whisper>=0.10.0

# Audio Language Models (Qwen-Audio requires special install)
# See: https://github.com/QwenLM/Qwen-Audio

# ==================== TRUE SOTA (Optional) ====================
# These are the absolute state-of-the-art models:

# emotion2vec: TRUE SOTA emotion recognition (Alibaba)
# Significantly outperforms wav2vec2-based models
# pip install funasr
# funasr>=1.0.0

# BEATs: TRUE SOTA audio event detection (Microsoft)
# 50.6% mAP on AudioSet, outperforms AST
# Available via transformers (microsoft/beats-iter3)

# DeepFilterNet: SOTA speech enhancement/noise reduction
# Real-time noise suppression with minimal speech distortion
# pip install deepfilternet
# deepfilternet>=0.5.0

# MusicGen: SOTA music generation (Meta)
# Text-to-music and melody-conditioned generation
# pip install audiocraft
# audiocraft>=1.2.0

# Silero VAD: Fast and accurate voice activity detection
# Used by streaming ASR for better segmentation
# torch.hub.load('snakers4/silero-vad', 'silero_vad')

# ==================== TRUE SOTA UPGRADES (Optional) ====================
# These upgrade existing features to absolute TRUE SOTA:

# StyleTTS2: TRUE SOTA Text-to-Speech (surpasses human recordings)
# Achieves MOS 4.4+ vs human 4.3 on LJSpeech
# pip install styletts2
# styletts2>=0.1.0
# Reference: https://github.com/yl4579/StyleTTS2

# SALMONN: TRUE SOTA Audio Captioning (generative, not retrieval)
# Speech Audio Language Music Open Neural Network
# pip install salmonn
# Reference: https://github.com/bytedance/SALMONN

# EINV2: TRUE SOTA Sound Event Localization and Detection
# Winner of DCASE 2023 SELD Challenge
# Uses ACCDOA output format for precise spatial audio
# Reference: https://github.com/sony/ai-research-code/tree/master/seld

# ==================== NICHE SOTA (Optional) ====================
# These are specialized features for advanced use cases:

# NISQA: Non-Intrusive Speech Quality Assessment
# CNN-LSTM neural network for MOS prediction
# pip install nisqa
# Reference: https://github.com/gabrielmittag/NISQA

# DNSMOS: Microsoft Deep Noise Suppression MOS
# Quality metric for noise suppression evaluation
# Available via onnxruntime (included in torch install)
# Reference: https://github.com/microsoft/DNS-Challenge

# SELD: Sound Event Localization and Detection
# Spatial audio understanding for multi-channel audio
# Uses AST/BEATs for detection (included via transformers)
# Reference: https://github.com/sharathadavanne/seld-dcase2022

# AudioLDM2: Diffusion-based audio generation and inpainting
# Text-to-audio, audio continuation, and inpainting
# pip install diffusers>=0.25.0
# diffusers>=0.25.0
# Reference: https://github.com/haoheliu/AudioLDM2
